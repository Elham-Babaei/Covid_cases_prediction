---
title: "analysis_Covid19"
author: "Imola Fodor"
date: "1/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Come diceva Auguste Compte: “Vedere per prevedere, prevedere per provvedere”. 

Load data

```{r }
data_all = read.csv("https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv")
attach(data_all)
data_all$date_only <- as.Date(data_all$data)
data_all$date_unix <- as.numeric(data_all$date_only)
data_subset = subset(data_all,denominazione_regione == "Veneto" & date_only >= "2020-08-01" & date_only < "2021-01-24")

#myvars <- c("terapia_intensiva","date_only","date_unix", "deceduti", "totale_casi", "nuovi_positivi", "note")
#data <- data_subset[myvars]


#Technically, in time series forecasting terminology the current time (t) and future times (t+1, t+n) are forecast times and past observations (t-1, t-n) are used to make forecasts.

#This permits not only classical X -> y prediction, but also X -> Y where both input and output can be sequences.

#Further, the shift function also works on so-called multivariate time series problems. That is where instead of having one set of observations for a time series, we have multiple (e.g. temperature and pressure). All variates in the time series can be shifted forward or backward to create multivariate input and output sequences.

#Multi-Step or Sequence Forecasting
#A different type of forecasting problem is using past observations to forecast a sequence of future observations.

#This may be called sequence forecasting or multi-step forecasting.

#We can frame a time series for sequence forecasting by specifying another argument. For example, we could frame our forecast problem with an input sequence of 14 past observations to forecast 14 future observations as follows:

data_subset$nlag <- 14

data_subset$lag_ti <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$terapia_intensiva[indx]
     else
        data_subset$terapia_intensiva[1]
})

data_subset$lag_tot_osp <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$totale_ospedalizzati[indx]
     else
        data_subset$totale_ospedalizzati[1]
})



data_subset$variazione_ti <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$terapia_intensiva[indx] - data_subset$terapia_intensiva[indx-1]
     else
        NULL
})

data_subset$variazione_deceduti <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$deceduti[indx] - data_subset$deceduti[indx-1]
     else
        NULL
})

data_subset$variazione_tot_osp <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$totale_ospedalizzati[indx] - data_subset$totale_ospedalizzati[indx-1]
     else
        NULL
})

data_subset$variazione_tot_pos_lag <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$totale_positivi[indx] - data_subset$totale_positivi[indx-1]
     else
        NULL
})


data_subset$variazione_ric_con_sintomi <- sapply(seq_along(data_subset$nlag), function(x) {
      indx = x - data_subset$nlag[x]
     if(indx > 0)
        data_subset$ricoverati_con_sintomi[indx] - data_subset$ricoverati_con_sintomi[indx-1]
     else
        NULL
})



data_subset$nuovi_dimessi_guariti <- sapply(seq_along(data_subset$nuovi_positivi), function(x) {
        data_subset$nuovi_positivi[x] - data_subset$variazione_totale_positivi[x]
})

#Moving average function that includes the current observation
mav <- function(x,n){stats::filter(x,rep(1/n,n), sides=1)}

#Moving average function that does not include the current observation
mavback <- function(x,n){
  a<-mav(x,1)
  b<-mav(x,(n+1))
  c<-(1/n)*((n+1)*b - a)
  return(c)
}

#Backward looking moving average function, not including current obs, based on [h2] readings starting [h1] periods back
mavback1<-function(x,h1,h2){
  a<-mavback(x,h1)
  b<-mavback(x,h1-h2)
  c<-(1/h2)*(h1*a -(h1-h2)*b)
  return(c)
}

data_subset$ma_ti <- mavback1(data_subset$terapia_intensiva,17,3)
data_subset$ma_decessi <- mavback1(data_subset$deceduti,17,3)
data_subset$ma_tot_osp <- mavback1(data_subset$totale_ospedalizzati,17,3)
data_subset$ma_tot_positivi <- mavback1(data_subset$totale_positivi,17,3)

#An article states there are 1016 beds in ti and 494 basic ones.
#https://www.dire.it/19-10-2020/152360-coronavirus-in-veneto-1-016-posti-per-la-terapia-intensiva-ma-non-ci-sono-i-medici/
#https://www.infodata.ilsole24ore.com/2020/10/15/terapie-intensive-scopri-in-tempo-reale-quanti-posti-sono-occupati/

data_subset$perc_esaurito_ti <- sapply(seq_along(data_subset$terapia_intensiva), function(x) {
        indx = x - data_subset$nlag[x]
        if(indx > 0)
          data_subset$terapia_intensiva[indx]*100/1016
        else
          0
})

library(dplyr)

data_subset <- data_subset %>% mutate(zona = case_when(
    (date_only < "2020-12-19"  & date_only > "2020-09-01") | (date_only < "2021-01-09" & date_only>"2021-01-06") |  date_only <= "2020-09-01"  ~ 1 ,
    (date_only < "2020-12-23"  & date_only > "2020-12-18") | (date_only < "2020-12-31"  & date_only > "2020-12-27") | date_only == "2021-01-04" | date_only > "2021-01-06" | (date_only < "2021-01-11" & date_only>"2021-01-08") ~ 2  ,
    (date_only < "2020-12-28"  & date_only > "2020-12-22") | (date_only < "2021-01-04"  & date_only > "2020-12-30") | (date_only >"2021-01-04" | date_only <"2021-01-07") ~ 3))

data_subset$nlagzona <- 14

data_subset$lag_zona <- sapply(seq_along(data_subset$nlagzona), function(x) {
      indx = x - data_subset$nlagzona[x]
     if(indx > 0)
        data_subset$zona[indx]
     else
        1
})

detach(data_all)
#(!complete.cases(data))
data = subset(data_subset,denominazione_regione == "Veneto" & date_only >= "2020-09-01" & date_only <= "2021-01-10")
#summary(data)
#columns <- names(data) # Extract column names from dataframe
#columns
#ls.str(data)
```

## Including Plots

You can also embed plots, for example:

```{r}
library(ggplot2)

myvars <- c("terapia_intensiva","deceduti", "totale_positivi")
data_subsubset <- data_subset[myvars]
scaled.data_subset <- data.frame(scale(data_subsubset))

ggplot() + geom_line(data = scaled.data_subset, aes(x=data_subset$date_only,y=terapia_intensiva), color="blue")+ geom_line(data=scaled.data_subset, aes(x=data_subset$date_only,y=deceduti),color = "red") + geom_line(data=scaled.data_subset, aes(x=data_subset$date_only,y=totale_positivi),color = "yellow")  + geom_vline(xintercept = as.numeric(as.Date("2021-01-10")), linetype=4) 
hist(data_subset$terapia_intensiva) #the data is not normally distributed
mean(data_subset$terapia_intensiva)
var(data_subset$terapia_intensiva) #The variance is much greater than the mean, which suggests that we will have over-dispersion in the model. The same goes for shooting stars: either the sky is empty, or littered with shooting stars. Such data would be overdispersed for a Poisson distribution
```

Predictors analysis

```{r}

#Missing "variazione_ti", "variazione_deceduti",
library(PerformanceAnalytics)
chart.Correlation(data[ ,c("terapia_intensiva", "ricoverati_con_sintomi", "totale_ospedalizzati", "isolamento_domiciliare", "totale_positivi", "variazione_totale_positivi", "nuovi_positivi", "dimessi_guariti", "deceduti", "totale_casi", "tamponi", "casi_testati", "lag_ti","lag_tot_osp","nuovi_dimessi_guariti", "ma_ti", "ma_decessi", "ma_tot_osp", "ma_tot_positivi", "perc_esaurito_ti", "lag_zona")])
```
Confront with the response variable, check correlation patterns (linear relationship, or at least a potential transformation)
```{r}
ggplot(data, aes(terapia_intensiva, perc_esaurito_ti))+geom_point()

ggplot(data, aes(terapia_intensiva, isolamento_domiciliare))+geom_point()
ggplot(data, aes(terapia_intensiva, totale_ospedalizzati))+geom_point()
ggplot(data, aes(terapia_intensiva, ricoverati_con_sintomi))+geom_point()
ggplot(data, aes(terapia_intensiva, nuovi_positivi))+geom_point()
ggplot(data, aes(terapia_intensiva, deceduti))+geom_point()

ggplot(data, aes(terapia_intensiva, ma_tot_osp))+geom_point() # no transormation applicable
ggplot(data, aes(terapia_intensiva, ma_ti))+geom_point()
ggplot(data, aes(terapia_intensiva, ma_decessi))+geom_point()

ggplot(data, aes(terapia_intensiva, lag_tot_osp))+geom_point()
ggplot(data, aes(terapia_intensiva, lag_ti))+geom_point()

ggplot(data, aes(terapia_intensiva, as.numeric(type.convert(variazione_ti))))+geom_point()
ggplot(data, aes(terapia_intensiva, as.numeric(type.convert(variazione_deceduti))))+geom_point()
ggplot(data, aes(terapia_intensiva, as.numeric(type.convert(variazione_tot_pos_lag))))+geom_point()
ggplot(data, aes(terapia_intensiva, as.numeric(type.convert(variazione_tot_osp))))+geom_point()


ggplot(data, aes(terapia_intensiva, zona))+geom_point()

```
Potential correlation between explanatory variables
```{r}
ggplot(subset(data, as.numeric(type.convert(variazione_tot_pos_lag)) > -6000), aes(as.numeric(type.convert(variazione_tot_pos_lag)), as.numeric(type.convert(variazione_tot_osp))))+geom_point()
ggplot(data, aes(ma_tot_osp, ma_ti))+geom_point() #quite a linear relationship, but excluding ma_tot_osp the model doesnt follow quite well the trend, even thoguh its closer to the values
ggplot(data, aes(ma_decessi, ma_ti))+geom_point()

ggplot(data, aes(as.numeric(type.convert(variazione_ric_con_sintomi)), as.numeric(type.convert(variazione_tot_osp))))+geom_point()
ggplot(data, aes( ma_ti, as.numeric(type.convert(variazione_ric_con_sintomi))))+geom_point()
ggplot(data, aes(ma_tot_osp, ma_ti))+geom_point()
```


Fitting the model

Poisson Regression helps us analyze both count data and rate data by allowing us to determine which explanatory variables (X values) have an effect on a given response variable (Y value, the count or a rate). For example, Poisson regression could be applied by a grocery store to better understand and predict the number of people in a line.

Here, μ (in some textbooks you may see λ instead of μ) is the average number of times an event may occur per unit of exposure. It is also called the parameter of Poisson distribution. The exposure may be time, space, population size, distance, or area, but it is often time, denoted with t. If exposure value is not given it is assumed to be equal to 1.

Plotting the data we are to fit.

```{r}
data$variazione_ti <- as.numeric(type.convert(data$variazione_ti))
data$variazione_deceduti <- as.numeric(type.convert(data$variazione_deceduti))
data$variazione_ric_con_sintomi <- as.numeric(type.convert(data$variazione_ric_con_sintomi))
data$variazione_tot_osp <- as.numeric(type.convert(data$variazione_tot_osp))

 
#poisson.model <- glm(terapia_intensiva ~ date_unix  + ma_decessi + ma_tot_osp + as.numeric(type.convert(variazione_tot_osp)) + perc_esaurito_ti, data = data, family = poisson(link = "log") ) # quite good, but not scaled variables
poisson.model <- glm(terapia_intensiva ~ date_unix  + ma_decessi + ma_tot_osp + as.numeric(type.convert(variazione_tot_osp)) + ma_tot_positivi + perc_esaurito_ti, data = data, family = poisson(link = "log") )
summary(poisson.model)
```
If the Residual Deviance is greater than the degrees of freedom, then over-dispersion exists. This means that the estimates are correct, but the standard errors (standard deviation) are wrong and unaccounted for by the model.

 We can use the residual deviance to perform a goodness of fit test for the overall model. The residual deviance is the difference between the deviance of the current model and the maximum deviance of the ideal model where the predicted values are identical to the observed. Therefore, if the residual difference is small enough, the goodness of fit test will not be significant, indicating that the model fits the data. We conclude that the model fits reasonably well because the goodness-of-fit chi-squared test is not statistically significant. If the test had been statistically significant, it would indicate that the data do not fit the model well. In that situation, we may try to determine if there are omitted predictor variables, if our linearity assumption holds and/or if there is an issue of over-dispersion.
 
```{r}
with(poisson.model, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```
So it doesn't fit well, p is stat. significant -> model doesnt fit. (?)

Let's plot

```{r}
plot(poisson.model)
```
```{r}
#Trying to improve the model, plotting the residuals vs true values of predictors
plot(data$ma_decessi, resid(poisson.model))
plot(data$ma_tot_osp, resid(poisson.model))
plot(data$ma_ti, resid(poisson.model))
plot(data$variazione_tot_pos_lag, resid(poisson.model))
abline(h=0, lty=2, col="darkgrey")
```



```{r}
dp = sum(residuals(poisson.model,type ="pearson")^2)/poisson.model$df.residual
dp
summary(poisson.model,dispersion = dp)
```
So, to have a more correct standard error we can use a quasi-poisson model:

```{r}
poisson.model2 <- glm(terapia_intensiva ~ date_unix + ma_decessi + ma_tot_osp:ma_ti, data = data, family = quasipoisson(link = "log"))
summary(poisson.model2)
```
Comparing the models

```{r}
library(arm)
# extract coefficients from first model using 'coef()'
coef1 = coef(poisson.model)

# extract coefficients from second model
coef2 = coef(poisson.model2)

# extract standard errors from first model using 'se.coef()'
se.coef1 = se.coef(poisson.model)

# extract standard errors from second model
se.coef2 = se.coef(poisson.model2)

# use 'cbind()' to combine values into one dataframe
models.both <- cbind(coef1, se.coef1, coef2, se.coef2, exponent = exp(coef1))

# show dataframe
models.both
```
Predicting

```{r}
# make a dataframe with new data
newdata = subset(data_subset,denominazione_regione == "Veneto" & date_only > "2021-01-10" & date_only < "2021-01-24")
#myvars <- c("terapia_intensiva", "date_unix, lag_ti","lag_tot_osp","variazione_ti", "variazione_deceduti","nuovi_dimessi_guariti", "ma_ti","ma_decessi", "ma_tot_osp", "perc_esaurito_ti", "date_only")
#newdata <- newdata[myvars]

# use 'predict()' to run model on new data
pred_pois = predict(poisson.model, newdata = newdata, type = "response")
pred_pois_quasi = predict(poisson.model2, newdata = newdata, type = "response")
```
Trying Negative Binomial since the data is overdispersed and the prediction is not the best.
An alternative approach to modeling over-dispersion in count data is to start
from a Poisson regression model and add a multiplicative random effect θ
to represent unobserved heterogeneity. This leads to the negative binomial
regression model.

```{r}
pred_pois
```


```{r}
summary(m1 <- glm.nb(terapia_intensiva ~date_unix + ma_decessi + ma_tot_osp + 
    ma_ti + as.numeric(type.convert(variazione_tot_pos_lag)) + 
    perc_esaurito_ti, data = data))
```

```{r}
m2 <- update(m1, . ~ . - ma_decessi)
anova(poisson.model, poisson.model2,m1, m2)
```
Checking binomial with poisson

```{r}
pchisq(2 * (logLik(m1) - logLik(poisson.model)), df = 381, lower.tail = FALSE) #this should prove its a binomial 
```
Predict with binomial

```{r}
pred_bin = predict(m1, newdata, type = "response")

  ggplot() + 
  geom_line(data = newdata, aes(x = date_only, y = pred_pois, color = "pois"), size=1 ) +
  geom_line(data = newdata, aes(x = date_only, y = pred_pois_quasi, color = "quasi pois"), size=1 ) +
  geom_line(data = newdata, aes(x = date_only, y = pred_bin, color = "neg binomial"), size=1) +
  geom_line(data = newdata, aes(x = date_only, y = terapia_intensiva, color = "empirical"),size=1) +
    
  scale_color_manual(name = "Fit", 
                     values = c("pois" = "lightblue", "quasi pois" = "orange", "neg binomial"="pink", "empirical"="darkgreen")) +
  xlab('Dates') +
  ylab('count in intensive care')
```


```{r}

data.lm1 <- lm(terapia_intensiva ~ date_unix, data = data)
data.lm2 <- lm(terapia_intensiva ~ date_unix + I(date_unix^2), data = data)
data.lm3 <- lm(terapia_intensiva ~ date_unix + I(date_unix^3)+I(date_unix^2), data = data)
data.lm4 <- lm(terapia_intensiva ~ date_unix + I(date_unix^4) + I(date_unix^3)+I(date_unix^2), data = data)

```

```{r}
summary(data.lm3)
```

```{r}
plot(data.lm1) #normality non stasified from the QQ plot
```


Applying polynomial regression of various degrees.

```{r}
plot(terapia_intensiva ~ date_unix, data = data, pch = 16,xlim = c(18500, 18650), cex=1.4)

lines(data$terapia_intensiva, predict(data.lm1), type="l", col="orange1", lwd=2)
lines(data$terapia_intensiva, predict(data.lm2), type="l", col="pink1", lwd=2)
lines(data$terapia_intensiva, predict(data.lm3), type="l", col="green", lwd=2)
lines(data$terapia_intensiva, predict(data.lm4), type="l", col="blue", lwd=2)
 
legend("topleft", 
        legend = c("y~x,  - linear","y~x+x^2", "y~ x+x^3+x^2", "y~ x+x^4+x^3+x^2"), 
        col = c("orange","pink","green","blue"),
        lty = 1, lwd=3
 ) 

```
```{r}
require(vcd)
require(MASS)

# data generation
ex <- data$terapia_intensiva # generate some exponential distribution
control <- abs(rnorm(10000)) # generate some other distribution

# estimate the parameters
fit1 <- fitdistr(ex, "exponential") 
fit2 <- fitdistr(control, "exponential")

# goodness of fit test
ks.test(ex, "pexp", fit1$estimate) # p-value > 0.05 -> distribution not refused
ks.test(control, "pexp", fit2$estimate) #  significant p-value -> distribution refused

# plot a graph
hist(ex, freq = FALSE, breaks = 100, xlim = c(0, quantile(ex, 0.99)))
curve(dexp(x, rate = fit1$estimate), from = 0, col = "red", add = TRUE)

hist(control, freq = FALSE, breaks = 100, xlim = c(0, quantile(control, 0.99)))
curve(dexp(x, rate = fit1$estimate), from = 0, col = "red", add = TRUE)
```

```{r}
#checking the assumption of normal distribution
library("scales")
ti_std <- rescale(data$terapia_intensiva)
library(fitdistrplus)
descdist(data$terapia_intensiva, discrete = TRUE)
plotdist(data$terapia_intensiva, discrete = TRUE)
fit.pois <- fitdist(data$terapia_intensiva, "pois")
plot(fit.pois)
```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
